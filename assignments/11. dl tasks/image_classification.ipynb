{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66f59c6d",
   "metadata": {},
   "source": [
    "## TensorFlow/Keras Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eace0e8",
   "metadata": {},
   "source": [
    "### Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1292d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D(2, 2),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37bbdfc",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1562f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.MobileNetV2(input_shape=(224, 224, 3), include_top=False, weights='imagenet')\n",
    "base_model.trainable = False  # freeze base\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7861cb",
   "metadata": {},
   "source": [
    "## PyTorch Version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d139f34",
   "metadata": {},
   "source": [
    "### Vanilla CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf50517",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.fc1 = nn.Linear(64*54*54, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf03b55a",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172a4dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)  # fine-tune last layer only"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc28596",
   "metadata": {},
   "source": [
    "Use sklearn.metrics.classification_report() and confusion_matrix() to show:\n",
    "\n",
    "- Class-wise precision, recall, F1-score\n",
    "\n",
    "- Confusion matrix heatmap using Seaborn\n",
    "\n",
    "- Plot training/validation accuracy & loss curves"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traineeship",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
